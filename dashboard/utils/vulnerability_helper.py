"""
Funciones auxiliares para el análisis de vulnerabilidad
"""

import pandas as pd
import numpy as np

def create_vulnerability_levels(df, column='criticidad_compuesta'):
    """
    Crea niveles de vulnerabilidad de forma robusta, manejando valores duplicados
    
    Args:
        df: DataFrame con los datos
        column: Columna a usar para crear los niveles
        
    Returns:
        Series con los niveles de vulnerabilidad
    """
    if column not in df.columns:
        # Si no existe la columna, usar Resultado como fallback
        if 'Resultado' in df.columns:
            return df['Resultado'].map({
                'Correcta': 'Baja',
                'Penalizada': 'Media',
                'Fallida': 'Alta'
            }).fillna('Media')
        else:
            return pd.Series(['Media'] * len(df), index=df.index)
    
    # Obtener valores únicos y ordenarlos
    valores = df[column].fillna(0)
    
    # Si todos los valores son iguales
    if valores.nunique() == 1:
        return pd.Series(['Media'] * len(df), index=df.index)
    
    # Intentar usar qcut con duplicates='drop'
    try:
        # Usar rank para manejar duplicados
        ranks = valores.rank(method='first')
        niveles = pd.qcut(
            ranks,
            q=[0, 0.2, 0.4, 0.6, 0.8, 1.0],
            labels=['Mínima', 'Baja', 'Media', 'Alta', 'Crítica']
        )
        return niveles
    except:
        # Si falla, usar cut con percentiles personalizados
        try:
            # Calcular percentiles únicos
            percentiles = [0, 20, 40, 60, 80, 100]
            bins = np.percentile(valores[valores > 0] if any(valores > 0) else valores, percentiles)
            bins = sorted(list(set(bins)))  # Eliminar duplicados
            
            if len(bins) < 2:
                return pd.Series(['Media'] * len(df), index=df.index)
            
            # Ajustar bins para que sean únicos
            bins[0] = bins[0] - 0.001  # Ajustar límite inferior
            bins[-1] = bins[-1] + 0.001  # Ajustar límite superior
            
            # Crear labels según cantidad de bins
            n_bins = len(bins) - 1
            all_labels = ['Mínima', 'Baja', 'Media', 'Alta', 'Crítica']
            if n_bins < 5:
                # Distribuir labels equitativamente
                step = 5 // n_bins
                labels = [all_labels[i * step] for i in range(n_bins)]
            else:
                labels = all_labels[:n_bins]
            
            niveles = pd.cut(
                valores,
                bins=bins,
                labels=labels,
                include_lowest=True
            )
            return niveles
        except:
            # Último recurso: clasificar por cuartiles simples
            if valores.std() == 0:
                return pd.Series(['Media'] * len(df), index=df.index)
            
            q1 = valores.quantile(0.25)
            q2 = valores.quantile(0.50)
            q3 = valores.quantile(0.75)
            
            def classify(x):
                if pd.isna(x) or x <= q1:
                    return 'Baja'
                elif x <= q2:
                    return 'Media'
                elif x <= q3:
                    return 'Alta'
                else:
                    return 'Crítica'
            
            return valores.apply(classify)

def get_vulnerability_colors():
    """Retorna el esquema de colores para niveles de vulnerabilidad"""
    return {
        'Crítica': '#d62728',    # Rojo
        'Alta': '#ff7f0e',       # Naranja
        'Media': '#ffdd57',      # Amarillo
        'Baja': '#2ca02c',       # Verde
        'Mínima': '#1f77b4'      # Azul
    }

def get_vulnerability_order():
    """Retorna el orden correcto de niveles de vulnerabilidad"""
    return ['Crítica', 'Alta', 'Media', 'Baja', 'Mínima']