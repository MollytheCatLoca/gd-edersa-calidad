# METODOLOG√çA CLAUDE - Framework para An√°lisis de Sistemas El√©ctricos con GD

## üìã Tabla de Contenidos
1. [Introducci√≥n](#introducci√≥n)
2. [Arquitectura de Software](#arquitectura-de-software)
3. [Flujo de Trabajo por Fases](#flujo-de-trabajo-por-fases)
4. [Directrices de Desarrollo](#directrices-de-desarrollo)
5. [Preparaci√≥n de Datos para ML](#preparaci√≥n-de-datos-para-ml)
6. [Buenas Pr√°cticas](#buenas-pr√°cticas)
7. [Plantillas y Herramientas](#plantillas-y-herramientas)

---

## üéØ Introducci√≥n

CLAUDE (Comprehensive Layout for Analysis of Utilities with Distributed Energy) es una metodolog√≠a estructurada para analizar sistemas el√©ctricos y evaluar la integraci√≥n de generaci√≥n distribuida (GD) con almacenamiento de energ√≠a (BESS).

### Casos de Uso
- An√°lisis de redes de distribuci√≥n con problemas de calidad
- Evaluaci√≥n t√©cnico-econ√≥mica de recursos distribuidos
- Optimizaci√≥n de ubicaci√≥n y dimensionamiento de GD+BESS
- Estudios de factibilidad para microrredes
- An√°lisis de p√©rdidas y mejora de voltaje

### Requisitos Previos
- Python 3.10+
- Conocimiento b√°sico de sistemas el√©ctricos
- Datos hist√≥ricos del sistema (ideal: 12+ meses, resoluci√≥n ‚â§15 min)

---

## üèóÔ∏è Arquitectura de Software

### Estructura Modular Est√°ndar

```
proyecto/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_loaders.py      # Carga y validaci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ data_analytics.py     # An√°lisis y KPIs
‚îÇ   ‚îú‚îÄ‚îÄ simulators.py         # Simulaciones del dominio
‚îÇ   ‚îú‚îÄ‚îÄ data_manager.py       # Coordinaci√≥n y API
‚îÇ   ‚îú‚îÄ‚îÄ constants.py          # Constantes del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ models.py             # Tipos de datos e interfaces
‚îú‚îÄ‚îÄ dashboard/                # Visualizaci√≥n interactiva
‚îú‚îÄ‚îÄ data/                     # Datos crudos y procesados
‚îú‚îÄ‚îÄ docs/                     # Documentaci√≥n
‚îî‚îÄ‚îÄ tests/                    # Pruebas unitarias
```

### Principios de Dise√±o

#### 1. Separaci√≥n de Responsabilidades
- **data_loaders.py**: Solo I/O y validaci√≥n
- **data_analytics.py**: C√°lculos y transformaciones
- **simulators.py**: L√≥gica espec√≠fica del dominio
- **data_manager.py**: Orquestaci√≥n sin l√≥gica de negocio

#### 2. Ubicaci√≥n de Funcionalidades

| Tipo de Funci√≥n | M√≥dulo | Ejemplos |
|-----------------|---------|----------|
| Carga/IO | `data_loaders.py` | Lectura CSV/Excel, validaci√≥n Pydantic |
| Anal√≠tica | `data_analytics.py` | KPIs, estad√≠sticas, agregaciones |
| Simulaci√≥n | `simulators.py` | Modelos FV, BESS, flujos de potencia |
| Coordinaci√≥n | `data_manager.py` | APIs, composici√≥n de resultados |
| Configuraci√≥n | `constants.py` | Par√°metros, umbrales, paths |

#### 3. Reglas de Evoluci√≥n

**REGLA FUNDAMENTAL**: No insertar l√≥gica de dominio en `data_manager.py`

**Checklist antes de a√±adir funciones:**
- [ ] Buscar si existe funcionalidad similar
- [ ] Verificar ubicaci√≥n correcta seg√∫n tabla
- [ ] Estimar complejidad (<150 LOC por funci√≥n)
- [ ] A√±adir tests y documentaci√≥n
- [ ] Actualizar constants/models si necesario

---

## üìä Flujo de Trabajo por Fases

### Fase 1: Comprensi√≥n del Sistema
**Objetivo**: Entender el problema y contexto

**Entradas**:
- Diagrama unifilar
- Datos de cargas y generaci√≥n
- Restricciones operativas

**Salidas**:
- Documento de comprensi√≥n del sistema
- Identificaci√≥n de puntos cr√≠ticos
- Hip√≥tesis iniciales

### Fase 2: Modelado Topol√≥gico
**Objetivo**: Representaci√≥n digital de la red

**Entradas**:
- Par√°metros de l√≠neas y transformadores
- Topolog√≠a de la red
- Puntos de medici√≥n

**Salidas**:
- Modelo topol√≥gico (JSON/GraphML)
- Matrices de admitancia
- Visualizaci√≥n de la red

### Fase 3: Procesamiento de Datos
**Objetivo**: Preparar datos para an√°lisis

**Pipeline Est√°ndar**:
```python
1. Validaci√≥n y limpieza
2. Detecci√≥n de anomal√≠as
3. Imputaci√≥n de faltantes
4. Feature engineering
5. Agregaciones temporales
6. Exportaci√≥n en formatos ML
```

**Salidas T√≠picas**:
- `summary.json`: Estad√≠sticas generales
- `quality_metrics.json`: Calidad de datos
- `temporal_patterns.json`: Patrones temporales
- `features.parquet`: Dataset para ML

### Fase 4: An√°lisis de Recursos Renovables
**Objetivo**: Modelar y simular GD+BESS

**Componentes**:
- Modelado de generaci√≥n FV
- Estrategias de control BESS
- An√°lisis de coincidencia demanda-generaci√≥n

### Fase 5: Evaluaci√≥n T√©cnica
**Objetivo**: Simular impacto en la red

**An√°lisis**:
- Flujos de potencia (AC/DC)
- Mejora de perfiles de voltaje
- Reducci√≥n de p√©rdidas
- An√°lisis de sensibilidad

### Fase 6: Evaluaci√≥n Econ√≥mica
**Objetivo**: Viabilidad financiera

**M√©tricas**:
- CAPEX/OPEX
- VAN, TIR, Payback
- LCOE
- An√°lisis de sensibilidad

---

## üõ†Ô∏è Directrices de Desarrollo

### Patrones de Nombrado
```python
# Prefijos est√°ndar
load_*()      # Funciones de carga
calc_*()      # C√°lculos
simulate_*()  # Simulaciones
optimize_*()  # Optimizaci√≥n
export_*()    # Exportaci√≥n
```

### Estructura de Resultados
```python
@dataclass
class DataResult:
    data: Any
    meta: Dict[str, Any]  # Debe incluir: source, version, timestamp
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
```

### Logging y Debug
```python
# Patr√≥n est√°ndar
logger.debug(f"{__name__}.{func_name}: Processing {len(data)} records")

# Para funciones con cache
logger.debug(f"Cache {'hit' if cached else 'miss'} for {hash(input_key)}")
```

---

## ü§ñ Preparaci√≥n de Datos para ML

### Features Est√°ndar

#### Temporales
- `hour`, `day_of_week`, `month`, `is_weekend`, `is_holiday`
- `season`, `is_peak_hour`, `time_since_midnight`

#### El√©ctricas
- `voltage_pu`, `power_mw`, `reactive_mvar`, `power_factor`
- `voltage_unbalance`, `thd_voltage`, `frequency_deviation`

#### Derivadas
- Rolling statistics (mean, std, min, max)
- Rampas y gradientes
- Lags (15min, 1h, 24h)
- Correlaciones cruzadas

### Formatos de Almacenamiento
- **Parquet**: Para datasets grandes (>100MB)
- **HDF5**: Para series temporales multidimensionales
- **JSON**: Para metadatos y configuraciones
- **CSV**: Para intercambio y visualizaci√≥n r√°pida

---

## ‚úÖ Buenas Pr√°cticas

### Gesti√≥n de Entornos
```bash
# Siempre usar entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Mantener requirements.txt actualizado
pip freeze > requirements.txt
```

### Control de Calidad
1. **Tests**: M√≠nimo 80% cobertura
2. **Documentaci√≥n**: Docstrings en todas las funciones p√∫blicas
3. **Type hints**: Usar tipado est√°tico
4. **Linting**: Black + Flake8
5. **CI/CD**: Tests autom√°ticos en cada PR

### Gesti√≥n de Complejidad
- Si funci√≥n > 150 LOC ‚Üí dividir
- Si m√≥dulo > 500 LOC ‚Üí considerar split
- Si dependencia nueva ‚Üí justificar en PR

---

## üìÅ Plantillas y Herramientas

### Plantilla de Proyecto
```bash
# Script de inicializaci√≥n
curl -O https://raw.githubusercontent.com/[repo]/init_claude_project.py
python init_claude_project.py --name "mi_proyecto"
```

### Dashboard Base
```python
# dashboard/app.py
import dash
from dash import dcc, html
import plotly.graph_objects as go

app = dash.Dash(__name__)

# Layouts por fase
from pages import fase1, fase2, fase3, fase4, fase5, fase6

app.layout = html.Div([
    dcc.Location(id='url', refresh=False),
    html.Div(id='page-content')
])

# Callback para navegaci√≥n multi-p√°gina
@app.callback(...)
def display_page(pathname):
    # L√≥gica de routing
    pass
```

### Configuraci√≥n T√≠pica
```python
# src/constants.py
from pathlib import Path

# Paths
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
PROCESSED_DIR = DATA_DIR / "processed"

# Par√°metros El√©ctricos
NOMINAL_VOLTAGE_KV = 33.0
VOLTAGE_LIMITS = {"min": 0.95, "max": 1.05}  # p.u.
BASE_MVA = 100

# Par√°metros Temporales
TIMESTAMP_FORMAT = "%Y-%m-%d %H:%M:%S"
DATA_FREQUENCY = "15min"

# Umbrales de Calidad
MAX_MISSING_DATA_PCT = 5.0
MIN_POWER_FACTOR = 0.85
```

---

## üöÄ Comenzar un Nuevo Proyecto

1. **Clonar estructura base**
```bash
git clone https://github.com/[template-repo] mi_proyecto
cd mi_proyecto
```

2. **Configurar constantes espec√≠ficas**
```python
# Editar src/constants.py con par√°metros del sistema
```

3. **Implementar cargadores de datos**
```python
# Adaptar data_loaders.py al formato de datos disponible
```

4. **Seguir las fases**
- Completar cada fase antes de avanzar
- Documentar decisiones y supuestos
- Validar resultados con expertos del dominio

---

## üìö Referencias y Recursos

- [Caso de Estudio: L√≠nea Sur](./CLAUDE.md) - Implementaci√≥n completa
- [Gu√≠a de Implementaci√≥n](./project/IMPLEMENTATION_GUIDE.md) - Paso a paso
- [FAQ y Troubleshooting](./FAQ.md) - Problemas comunes

---

**Versi√≥n**: 1.0.0  
**√öltima actualizaci√≥n**: Julio 2025  
**Licencia**: MIT